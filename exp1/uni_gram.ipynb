{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理，将文本处理成单词列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    sentences = text.split(\"__eou__\")  # 分句\n",
    "    sentences.pop()\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(r\"[^\\w\\s']\", \"\", sentence).lower()  # 去除标点，改为小写\n",
    "        words += word_tokenize(sentence)  # 分词\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理，将文本处理成二维列表，text列表存储sentence列表，sentence存这个句子的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text2(text):\n",
    "    sentences = text.split(\"__eou__\")\n",
    "    sentences.pop()\n",
    "    text = []\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(r\"[^\\w\\s']\", \"\", sentence).lower()\n",
    "        text.append(word_tokenize(sentence))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建词汇表，vocab为字典，每个项的格式为{word:count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(words):\n",
    "    vocab = Counter(words)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算unigram概率（加一平滑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unigram_probs(vocab, total_words):\n",
    "    unigram_probs = {}\n",
    "    for word, count in vocab.items():\n",
    "        unigram_probs[word] = (count + 1) / (total_words + len(vocab))\n",
    "    return unigram_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算句子困惑度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_perplexity(text, unigram_probs, vocab, total_words):\n",
    "    perplexity = []\n",
    "    for sentence in text:\n",
    "        prob = 0\n",
    "        for word in sentence:\n",
    "            if word in unigram_probs:\n",
    "                prob += log2(unigram_probs[word])\n",
    "            else:\n",
    "                prob += log2(1 / (len(vocab) + total_words))  # 未知单词的概率\n",
    "        perplexity.append(pow(2, -(prob / len(sentence))))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估文本困惑度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_perplexity(perplexity):\n",
    "    return sum(perplexity) / len(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902.3264658565882\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_LM.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    train_text = file.read()\n",
    "with open(\"test_LM.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    test_text = file.read()\n",
    "\n",
    "words = preprocess_text(train_text)  # 单词列表\n",
    "vocab = build_vocab(words)  # 词汇表\n",
    "unigram_probs = calculate_unigram_probs(vocab, len(words))  # unigram概率\n",
    "test_text = preprocess_text2(test_text)  # text二维列表\n",
    "perplexity = sentence_perplexity(test_text, unigram_probs, vocab, len(words))  # 句子困惑度列表\n",
    "test_perplexity = text_perplexity(perplexity)  # 文本困惑度\n",
    "\n",
    "print(test_perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
